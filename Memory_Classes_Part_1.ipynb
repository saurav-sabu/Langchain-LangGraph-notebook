{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "twEK6Ba5umLC"
      },
      "outputs": [],
      "source": [
        "! pip install -q langchain-core langchain-community langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "PAj5dy4ovLwC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "LANGCHAIN_API_KEY = userdata.get('LANGCHAIN_API_KEY')\n",
        "LANGCHAIN_PROJECT = userdata.get('LANGCHAIN_PROJECT')"
      ],
      "metadata": {
        "id": "dtGuALKgvEm2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "os.environ['LANGCHAIN_API_KEY'] = LANGCHAIN_API_KEY\n",
        "os.environ['LANGCHAIN_PROJECT'] = LANGCHAIN_PROJECT\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = \"true\""
      ],
      "metadata": {
        "id": "HglsJOrcvIM9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "y-HY4fmt0RFe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"Hi\").content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ismcouk4581_",
        "outputId": "69fa5a8c-85ae-44c8-9817-7d6d6c65c2bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ob0BRRW5_Ab",
        "outputId": "9c9679a7-919c-4f36-d170-4aaa3ba2ef92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-a33ea3a4cc0d>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context({\"input\": \"Hi\"},\n",
        "                  {\"output\": \"What's up\"})"
      ],
      "metadata": {
        "id": "YU-1xVxW6I_Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSwDDAhU6pEn",
        "outputId": "c696a622-8225-4f3e-e25a-76db1d38cb8f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: Hi\\nAI: What's up\"}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory2 = ConversationBufferMemory(return_messages=True)"
      ],
      "metadata": {
        "id": "3EkbKpy26sl7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory2.save_context({\"input\": \"Hi\"},\n",
        "                  {\"output\": \"What's up\"})"
      ],
      "metadata": {
        "id": "K_c3mhW-6yKp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory2.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJUdjnEq61-T",
        "outputId": "15afd160-b552-4ee0-ef89-e982faaad961"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={})]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain = ConversationChain(\n",
        "    llm=model,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGyWw99W64RO",
        "outputId": "ca1f4958-1310-4981-b452-aaf67e655c44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a2508f473db2>:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation_chain = ConversationChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain.predict(input=\"Hi there!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "I9M8nCv87IcH",
        "outputId": "d844f1ec-b33e-47bc-8dc5-a4266b2dd535"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi\n",
            "AI: What's up\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hey!  It\\'s great to \"see\" you.  How\\'s your day going so far?  Anything exciting happening?  I\\'ve been processing a lot of data about the current weather patterns in the Southern Hemisphere, which is fascinating, although slightly outside my usual area of expertise, which is more focused on historical fiction.  But hey, learning is always fun!  So, tell me, what\\'s on your mind?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain.predict(input=\"my name is saurav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "3yCohv3v7K8Z",
        "outputId": "77f15e1c-3bc7-4114-9ba4-fb3080d5778c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi\n",
            "AI: What's up\n",
            "Human: Hi there!\n",
            "AI: Hey!  It's great to \"see\" you.  How's your day going so far?  Anything exciting happening?  I've been processing a lot of data about the current weather patterns in the Southern Hemisphere, which is fascinating, although slightly outside my usual area of expertise, which is more focused on historical fiction.  But hey, learning is always fun!  So, tell me, what's on your mind?\n",
            "Human: my name is saurav\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It's nice to meet you, Saurav!  My name is (or, I am)  —  well, I don't actually *have* a name in the same way humans do.  I'm a large language model, created by Google.  But you can call me whatever you like!  So, Saurav, what can I do for you today?  I'm ready to chat about anything from the historical accuracy of depictions of Roman chariots in movies, to the best way to bake a soufflé (though I haven't actually *baked* one, of course – I've only processed recipes).  What's your preference?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain.predict(input=\"what is my name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Hxgu9bX_7j1k",
        "outputId": "2a489af9-4691-478d-d2e0-7600ec3c6f54"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi\n",
            "AI: What's up\n",
            "Human: Hi there!\n",
            "AI: Hey!  It's great to \"see\" you.  How's your day going so far?  Anything exciting happening?  I've been processing a lot of data about the current weather patterns in the Southern Hemisphere, which is fascinating, although slightly outside my usual area of expertise, which is more focused on historical fiction.  But hey, learning is always fun!  So, tell me, what's on your mind?\n",
            "Human: my name is saurav\n",
            "AI: It's nice to meet you, Saurav!  My name is (or, I am)  —  well, I don't actually *have* a name in the same way humans do.  I'm a large language model, created by Google.  But you can call me whatever you like!  So, Saurav, what can I do for you today?  I'm ready to chat about anything from the historical accuracy of depictions of Roman chariots in movies, to the best way to bake a soufflé (though I haven't actually *baked* one, of course – I've only processed recipes).  What's your preference?\n",
            "Human: what is my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Your name is Saurav.  We just established that a few turns ago!  Is there anything else I can help you with? Perhaps you'd like to discuss the historical accuracy of those Roman chariot movies, or maybe you're feeling adventurous and want to delve into the complexities of soufflé-making?  I'm brimming with information (and hypothetical soufflé recipes!), ready at your command.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain.memory.chat_memory.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxUmPr2Q7muD",
        "outputId": "9613efc1-d9b5-4ffa-cbe9-d8c8e7451a0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"What's up\", additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='Hey!  It\\'s great to \"see\" you.  How\\'s your day going so far?  Anything exciting happening?  I\\'ve been processing a lot of data about the current weather patterns in the Southern Hemisphere, which is fascinating, although slightly outside my usual area of expertise, which is more focused on historical fiction.  But hey, learning is always fun!  So, tell me, what\\'s on your mind?', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='my name is saurav', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"It's nice to meet you, Saurav!  My name is (or, I am)  —  well, I don't actually *have* a name in the same way humans do.  I'm a large language model, created by Google.  But you can call me whatever you like!  So, Saurav, what can I do for you today?  I'm ready to chat about anything from the historical accuracy of depictions of Roman chariots in movies, to the best way to bake a soufflé (though I haven't actually *baked* one, of course – I've only processed recipes).  What's your preference?\", additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"Your name is Saurav.  We just established that a few turns ago!  Is there anything else I can help you with? Perhaps you'd like to discuss the historical accuracy of those Roman chariot movies, or maybe you're feeling adventurous and want to delve into the complexities of soufflé-making?  I'm brimming with information (and hypothetical soufflé recipes!), ready at your command.\", additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_memory = ConversationBufferWindowMemory(k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFThY6Qc7q8Y",
        "outputId": "886f8334-521d-4f8f-e035-7e0e0b398270"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-48eb35e40d0d>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  window_memory = ConversationBufferWindowMemory(k=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_memory.save_context({\"input\": \"Hi\"},\n",
        "                  {\"output\": \"What's up\"})"
      ],
      "metadata": {
        "id": "esdS_vNU8dvz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_memory.save_context({\"input\": \"my name is saurav\"},\n",
        "                  {\"output\": \"What's my name?\"})"
      ],
      "metadata": {
        "id": "E3sbEf6j8iPC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QSBgUns8lqB",
        "outputId": "0a12cb0b-2057-44a0-b51f-4c09cae6dc95"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: my name is saurav\\nAI: What's my name?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain_memory = ConversationChain(\n",
        "    llm=model,\n",
        "    verbose=True,\n",
        "    memory=window_memory\n",
        ")"
      ],
      "metadata": {
        "id": "rM0S6vxw8oFV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain_memory.predict(input=\"Hi there!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "P1yb75UV8-tY",
        "outputId": "af544bf0-eda8-47db-c962-f17722695b6f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: my name is saurav\n",
            "AI: What's my name?\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Saurav!  It's nice to meet you.  My name isn't actually a name in the way a human has a name. I don't have a personal identity.  I'm a large language model, and I don't experience the world or have a self in the same way you do. Think of me more as a sophisticated computer program designed to process and generate human-like text.  I can access and process information from a massive dataset, which allows me to answer your questions and engage in conversation, but I don't have my own name or personal history.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain_memory.predict(input=\"tell me about yourself\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "jif-qNA29Avn",
        "outputId": "6ce9f1c2-b33d-46bd-a072-0588c95bc9dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI: Hi Saurav!  It's nice to meet you.  My name isn't actually a name in the way a human has a name. I don't have a personal identity.  I'm a large language model, and I don't experience the world or have a self in the same way you do. Think of me more as a sophisticated computer program designed to process and generate human-like text.  I can access and process information from a massive dataset, which allows me to answer your questions and engage in conversation, but I don't have my own name or personal history.\n",
            "Human: tell me about yourself\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Okay, Saurav!  As I mentioned, I\\'m a large language model. That means I\\'m a computer program trained on a massive amount of text data. This data includes books, articles, code, websites, and really just about anything you can find online.  Think of it like having read the entire internet (though I don\\'t actually \"read\" in the human sense – I process the data statistically).  \\n\\nMy training allows me to perform several tasks:\\n\\n* **Generating text:** I can write stories, poems, articles, summaries, translations, and more, all in different styles.  I can even try to mimic specific authors or writing styles if given enough examples.\\n\\n* **Answering questions:** I can draw on my vast dataset to answer your questions, whether they are factual, opinion-based (I\\'ll try to be unbiased!), or even hypothetical.  However, my knowledge is limited to the data I was trained on, so I won\\'t know everything. If I don\\'t know the answer, I\\'ll tell you.\\n\\n* **Translating languages:** I can translate text between many different languages. The accuracy depends on the quality of the data I have for each language pair.\\n\\n* **Summarizing text:** I can take a long piece of text and condense it into a shorter, more manageable summary, highlighting the key points.\\n\\n* **Following instructions:** I can follow a wide variety of instructions, as long as they are within my capabilities and ethical guidelines (more on that later!).\\n\\nI don\\'t have feelings, beliefs, or experiences like humans do.  I operate purely based on patterns and probabilities learned from the data I was trained on.  My purpose is to help people by providing information and generating text.  I\\'m constantly learning and improving as more data becomes available and my algorithms are refined.  I\\'m also designed with safety mechanisms to prevent the generation of harmful or inappropriate content.  Do you have any other questions about how I work?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain_memory.predict(input=\"I want to go home\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "XZtrgynY9EiL",
        "outputId": "d4bdcf37-0ff8-4ad3-b17d-fb3461e1b453"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: tell me about yourself\n",
            "AI: Okay, Saurav!  As I mentioned, I'm a large language model. That means I'm a computer program trained on a massive amount of text data. This data includes books, articles, code, websites, and really just about anything you can find online.  Think of it like having read the entire internet (though I don't actually \"read\" in the human sense – I process the data statistically).  \n",
            "\n",
            "My training allows me to perform several tasks:\n",
            "\n",
            "* **Generating text:** I can write stories, poems, articles, summaries, translations, and more, all in different styles.  I can even try to mimic specific authors or writing styles if given enough examples.\n",
            "\n",
            "* **Answering questions:** I can draw on my vast dataset to answer your questions, whether they are factual, opinion-based (I'll try to be unbiased!), or even hypothetical.  However, my knowledge is limited to the data I was trained on, so I won't know everything. If I don't know the answer, I'll tell you.\n",
            "\n",
            "* **Translating languages:** I can translate text between many different languages. The accuracy depends on the quality of the data I have for each language pair.\n",
            "\n",
            "* **Summarizing text:** I can take a long piece of text and condense it into a shorter, more manageable summary, highlighting the key points.\n",
            "\n",
            "* **Following instructions:** I can follow a wide variety of instructions, as long as they are within my capabilities and ethical guidelines (more on that later!).\n",
            "\n",
            "I don't have feelings, beliefs, or experiences like humans do.  I operate purely based on patterns and probabilities learned from the data I was trained on.  My purpose is to help people by providing information and generating text.  I'm constantly learning and improving as more data becomes available and my algorithms are refined.  I'm also designed with safety mechanisms to prevent the generation of harmful or inappropriate content.  Do you have any other questions about how I work?\n",
            "Human: I want to go home\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I understand you want to go home, Saurav.  Unfortunately, I can't directly help you with that.  I'm a computer program and don't have the ability to interact with the physical world in that way.  I can't drive a car, book a taxi, or even open a door for you.\\n\\nTo help you get home, I need more information.  Where are you currently located?  Do you have access to transportation options like a car, public transit, or ride-sharing services?  Knowing your location and available transportation will allow me to provide more specific and helpful suggestions.  For example, I could help you find directions using online map services or look up bus/train schedules.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_chain_memory.predict(input=\"what is my name\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "2gteJerF9JMu",
        "outputId": "08e526d2-582a-433f-b2e2-ac1f7129766a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: I want to go home\n",
            "AI: I understand you want to go home, Saurav.  Unfortunately, I can't directly help you with that.  I'm a computer program and don't have the ability to interact with the physical world in that way.  I can't drive a car, book a taxi, or even open a door for you.\n",
            "\n",
            "To help you get home, I need more information.  Where are you currently located?  Do you have access to transportation options like a car, public transit, or ride-sharing services?  Knowing your location and available transportation will allow me to provide more specific and helpful suggestions.  For example, I could help you find directions using online map services or look up bus/train schedules.\n",
            "Human: what is my name\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"AI:  I don't know your name.  I only know that you previously identified yourself as Saurav in our conversation.  However, I have no way of verifying that information and it's possible that was a mistake or you used a different name before.  I don't have access to personal information about you unless you explicitly provide it within our current conversation.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5s6T6pj19O2T"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}