{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain V1 Agents"
      ],
      "metadata": {
        "id": "F7z9QVGstobn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdiZAM2rs-dl",
        "outputId": "128f3861-5595-4ab1-8d3f-4dd7da24b78d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip -q install langchain-community langchain-core langgraph langserve langchain-google-genai wikipedia faiss-cpu langchain-openai google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "from langchain.agents import tool, AgentExecutor, create_react_agent, Tool, create_self_ask_with_search_agent\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools, create_tool_calling_agent\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain import hub\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "8MhgJNaqt5IZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "SERPAPI_API_KEY = userdata.get('SERPAPI_API_KEY')\n",
        "GOOGLE_CSE_ID = userdata.get('GOOGLE_CSE_ID')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"SERPAPI_API_KEY\"] = SERPAPI_API_KEY\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "Gvfb_86Ct55h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "J0KQ9Qtot8vl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "29VRHq-u5bSn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool Calling Agent"
      ],
      "metadata": {
        "id": "jGLIVD4QwsOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ],
      "metadata": {
        "id": "17Xp3E8CwqIy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = TavilySearchResults()"
      ],
      "metadata": {
        "id": "HSK3XKOSxFX5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.invoke(\"What is LangChain?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrprQMzKxH-F",
        "outputId": "18ba4689-08d1-4b57-b681-20aeb4572b72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://python.langchain.com/docs/introduction/',\n",
              "  'content': \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\"},\n",
              " {'url': 'https://www.geeksforgeeks.org/introduction-to-langchain/',\n",
              "  'content': 'Data Structures and Algorithms\\nML & Data Science\\nWeb Development\\nLanguages\\nInterview Corner\\nCS Subjects\\nJobs\\nPractice\\nContests\\nIntroduction to Langchain\\nLangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). LangChain follows a general pipeline where a user asks a question to the language model where the vector representation of the question is used to do a similarity search in the vector database and the relevant information is fetched from the vector database and the response is later fed to the language model. LangChain Key Concepts:\\nThe main properties of LangChain Framework are :\\nSetting up the environment\\nInstallation of langchain is very simple and similar as you install other libraries using the pip command.\\n Next, we create a .env file and store our API key in it as follows:\\nPython\\nNow, I am creating a new file named ‘lang.py’ where I will be using the LangChain framework to generate responses. We start by importing long-chain and initializing an LLM as follows:\\nPython\\nWe are initializing it with a high temperature which means that the results will be random and less accurate.'},\n",
              " {'url': 'https://datasciencedojo.com/blog/what-is-langchain/',\n",
              "  'content': 'LangChain stands out by simplifying the development and deployment of LLM-powered applications, making it easier for businesses to integrate advanced AI capabilities into their processes. By integrating LLMs with real-time data and external knowledge bases, LangChain empowers businesses to create more sophisticated and responsive AI applications, driving innovation and improving service delivery across various sectors. From modular components that simplify complex tasks to advanced prompt engineering and seamless integration with external data sources, LangChain offers everything developers need to build powerful, intelligent applications. LangChain provides a set of tools and components that help integrate LLMs with other data sources and computation tools, making it easier to build sophisticated AI applications like chatbots, content generators, and data retrieval systems.'},\n",
              " {'url': 'https://en.wikipedia.org/wiki/LangChain',\n",
              "  'content': 'In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]'},\n",
              " {'url': 'https://www.techtarget.com/searchEnterpriseAI/definition/LangChain',\n",
              "  'content': \"Everything you need to know\\nWhat are the features of LangChain?\\nLangChain is made up of the following modules that ensure the multiple components needed to make an effective NLP app can run smoothly:\\nWhat are the integrations of LangChain?\\nLangChain typically builds applications using integrations with LLM providers and external sources where data can be found and stored. What is synthetic data?\\nExamples and use cases for LangChain\\nThe LLM-based applications LangChain is capable of building can be applied to multiple advanced use cases within various industries and vertical markets, such as the following:\\nReaping the benefits of NLP is a key of why LangChain is important. As the airline giant moves more of its data workloads to the cloud, tools from Intel's Granulate are making platforms such as ...\\nThe vendor's new platform, now in beta testing, combines its existing lakehouse with AI to better enable users to manage and ...\\n The following steps are required to use this:\\nIn this scenario, the language model would be expected to take the two input variables -- the adjective and the content -- and produce a fascinating fact about zebras as its output.\\n The goal of LangChain is to link powerful LLMs, such as OpenAI's GPT-3.5 and GPT-4, to an array of external data sources to create and reap the benefits of natural language processing (NLP) applications.\\n\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [search]"
      ],
      "metadata": {
        "id": "Q0M8eRStxKRw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JsF3-vWxPF-",
        "outputId": "442a348d-2bd1-4442-92b8-dbb0651cf513"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1Zu9NXLxVxU",
        "outputId": "ecc6b14f-25ad-433b-9c0c-96b52cb91642"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7fcca6e8f1a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7fcca6e8f1a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ufkZdhxX0h",
        "outputId": "f69b0dc6-b7e3-4c22-d8cf-34aa4d7051a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_tool_calling_agent(llm,tools,prompt)"
      ],
      "metadata": {
        "id": "swuWfShVxZjN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "yQz9e99Oxjif"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\":\"tell me about yourself\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX_LSOZNxmCa",
        "outputId": "f790f14f-dcf3-4f5d-b350-f7e23700ab8a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI am an AI assistant here to help you with any questions or tasks you may have. Feel free to ask me anything, and I'll do my best to assist you!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'tell me about yourself',\n",
              " 'output': \"I am an AI assistant here to help you with any questions or tasks you may have. Feel free to ask me anything, and I'll do my best to assist you!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Tool"
      ],
      "metadata": {
        "id": "Jg5BEUNDya7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPgXsgJAxtkq",
        "outputId": "74e957fb-5b85-47a7-a38b-ac890b8fa373"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\"https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "b22x_-wWyvmD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tmIIgBYy24c",
        "outputId": "068fb1f4-5385-490c-e1c7-a3062d008992"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/', 'title': 'LangGraph Studio: The first agent IDE', 'description': 'LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.', 'language': 'en'}, page_content=\"\\n\\n\\nLangGraph Studio: The first agent IDE\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Studio: The first agent IDE\\nLangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.\\n\\n4 min read\\nAug 1, 2024\\n\\n\\n\\n\\n\\nLLMs have paved the way for the development of new types of agentic applications ‚Äî and as LLM applications evolve, so must the tooling needed to efficiently develop them. Today, we're announcing LangGraph Studio - the first IDE designed specifically for agent development - in open beta.LangGraph Studio offers a new way to develop LLM applications, providing a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. In this blog, we'll give a brief overview of LangGraph and then explore how LangGraph Studio streamlines the development of agentic applications.LangGraph: Balancing agent control with agency  In January 2023, we launched LangGraph, a highly controllable, low-level orchestration framework for building agentic applications. Since then, we've seen  teams build more complex agentic applications for production; in turn, we've heavily invested in LangGraph, leading to a stable 0.1 release this past June.LangGraph features a persistence layer that enables human-in-the-loop interactions, and it excels at building complex (i.e. more than a single LLM call) applications that require highly domain-specific cognitive architecture. Most of the agents we see in production fit this description.LangGraph is fully open source, available in both Python and Javascript. It works with or without LangChain, and integrates seamlessly with LangSmith.LangGraph Studio: Visualize and interact with agent graphs for quick iterationWhile LangGraph offers a new framework for developing agentic applications, we also strongly believe that new tooling is needed to make the development process easier. Building LLM applications differs from traditional software development, requiring different tooling outside of the traditional code editor.Coding is still important to developing LLM applications ‚Äî after all, production-ready LangGraph applications have complicated custom logic in the nodes and edges of the graphs that are created. We don't aim to replace code editors but, instead, to augment the development experience with tools tailored for LangGraph applications. LangGraph Studio facilitates this by making it easy to visualize and interact with agent graphs, even if development still primarily happens in code. Visualizing graphs helps developers understand their structure. Furthermore, you can modify an agent result (or the logic underlying a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more to explore, we're excited to introduce LangGraph Studio to start with bringing some of the core features of an agent IDE to the world.How to use LangGraph StudioLangGraph Studio is a desktop app, currently available for Apple Silicon. You can download a version here. Support for more platforms is coming soon.After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. You can sign up for a LangSmith account here.After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it. Next, you will need to create a langgraph.json file containing details such as where the agent is defined, which dependencies to install, and which environment variables to load. This file can be created in the UI, or can exist as a file in the directory already. For an example repository which meets these requirements, see this GitHub repo.After you open a directory, we will build an environment for you agent to run. After it builds, you should see a visualization of the graph along with a box for interacting with the agent.When you interact with the agent, you'll get a stream of real-time information about what steps are happening. You can see the agent decide which tools to call, call those tools, and then continue looping. You can interrupt the agent at any time if veers off course, or you can interrupt the agent to run it in a ‚Äúdebug mode‚Äù where it pauses after each step of the graph (so you can walk-through step by step).\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:19\\n\\n\\n1√ó\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\uf8ffüí°At any point, you can interact with the state of the agent.If you don‚Äôt like what the agent responded with at a specific step, you can directly modify the response and then continue with that new response. This can be useful for simulating what would have happened if the agent or a tool returned something different.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:14\\n\\n\\n1√ó\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYou can also modify the underlying code and then replay the node. LangGraph Studio detects changes to the underlying code files, allowing you to update prompts in your code editor and rerun nodes if an agent responds poorly. This can make it much easier to iterate on long-running agents.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n0:00\\n\\n                            /0:20\\n\\n\\n1√ó\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nConclusionBuilding agentic applications differs from traditional software development. While code editors remain important, new IDEs designed for agents are also needed. LangGraph Studio is a step in this direction, and we're excited to see how it enhances your workflow.For more on LangGraph Studio, check out our documentation. You can also watch a video walkthrough on YouTube if that's more your style. You can\\xa0sign up for LangSmith\\xa0today to try out LangGraph Studio for free.We'd also love your feedback - drop us a line at hello@langchain.dev or on Twitter to share your thoughts.\\n\\n\\nJoin our newsletter\\nUpdates from the LangChain team and community\\n\\n\\nEnter your email\\n\\nSubscribe\\n\\nProcessing your application...\\nSuccess! Please check your inbox and click the link to confirm your subscription.\\nSorry, something went wrong. Please try again.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSign up\\n\\n\\n\\n\\n\\n            ¬© LangChain Blog 2025\\n        \\n\\n\\n\\n\\n\\n\\n\")]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "LPH0oNqBy4oH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = FAISS.from_documents(chunks, embedding)\n",
        "retriever = vector.as_retriever()"
      ],
      "metadata": {
        "id": "-xwWhfDCzAYB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"What is LangGraph\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFbg8UsgzGHR",
        "outputId": "ba4387d7-dd1e-4e9c-dbbe-516cdf370e15"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='465563d0-098a-4b89-993d-925788f28cbd', metadata={'source': 'https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/', 'title': 'LangGraph Studio: The first agent IDE', 'description': 'LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.', 'language': 'en'}, page_content=\"Since then, we've seen  teams build more complex agentic applications for production; in turn, we've heavily invested in LangGraph, leading to a stable 0.1 release this past June.LangGraph features a persistence layer that enables human-in-the-loop interactions, and it excels at building complex (i.e. more than a single LLM call) applications that require highly domain-specific cognitive architecture. Most of the agents we see in production fit this description.LangGraph is fully open source, available in both Python and Javascript. It works with or without LangChain, and integrates seamlessly with LangSmith.LangGraph Studio: Visualize and interact with agent graphs for quick iterationWhile LangGraph offers a new framework for developing agentic applications, we also strongly believe that new tooling is needed to make the development process easier. Building LLM applications differs from traditional software development, requiring different tooling outside of the traditional code\"),\n",
              " Document(id='dec90342-33bd-43c7-a906-2d75f7862839', metadata={'source': 'https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/', 'title': 'LangGraph Studio: The first agent IDE', 'description': 'LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.', 'language': 'en'}, page_content=\"LLMs have paved the way for the development of new types of agentic applications ‚Äî and as LLM applications evolve, so must the tooling needed to efficiently develop them. Today, we're announcing LangGraph Studio - the first IDE designed specifically for agent development - in open beta.LangGraph Studio offers a new way to develop LLM applications, providing a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. In this blog, we'll give a brief overview of LangGraph and then explore how LangGraph Studio streamlines the development of agentic applications.LangGraph: Balancing agent control with agency  In January 2023, we launched LangGraph, a highly controllable, low-level orchestration framework for building agentic applications. Since then, we've seen  teams build more complex agentic applications for production; in turn, we've heavily invested in LangGraph, leading to a stable 0.1 release this past June.LangGraph features a\"),\n",
              " Document(id='e5a7ffaf-9092-46c8-9cde-7acfc86f520a', metadata={'source': 'https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/', 'title': 'LangGraph Studio: The first agent IDE', 'description': 'LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.', 'language': 'en'}, page_content=\"(or the logic underlying a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more to explore, we're excited to introduce LangGraph Studio to start with bringing some of the core features of an agent IDE to the world.How to use LangGraph StudioLangGraph Studio is a desktop app, currently available for Apple Silicon. You can download a version here. Support for more platforms is coming soon.After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. You can sign up for a LangSmith account here.After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it. Next, you will need to create a langgraph.json\"),\n",
              " Document(id='9bff9260-2dea-44d4-b43a-b8fe6c9ef006', metadata={'source': 'https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/', 'title': 'LangGraph Studio: The first agent IDE', 'description': 'LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.', 'language': 'en'}, page_content='LangGraph Studio: The first agent IDE\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangGraph Studio: The first agent IDE\\nLangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.\\n\\n4 min read\\nAug 1, 2024')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_tool = create_retriever_tool(retriever,\n",
        "                                       \"langchain\",\n",
        "                                       \"search from the langchain documentation\")"
      ],
      "metadata": {
        "id": "UCeFuiyWzMtT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [search,retriever_tool]"
      ],
      "metadata": {
        "id": "CJy8rot9zfKy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_tool_calling_agent(llm,tools,prompt)"
      ],
      "metadata": {
        "id": "HP4nFlhUziBk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "UFZlM2HJzmDQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\":\"What is LangGraph\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmcazQ4pzpq4",
        "outputId": "09326560-16b6-4bbf-8509-4426ae1711f4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `langchain` with `{'query': 'LangGraph'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mLangGraph Studio: The first agent IDE\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skip to content\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Case Studies\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "In the Loop\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "LangChain\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Docs\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Changelog\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sign in\n",
            "Subscribe\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "LangGraph Studio: The first agent IDE\n",
            "LangGraph Studio provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. See how to use it on your desktop today.\n",
            "\n",
            "4 min read\n",
            "Aug 1, 2024\n",
            "\n",
            "Since then, we've seen  teams build more complex agentic applications for production; in turn, we've heavily invested in LangGraph, leading to a stable 0.1 release this past June.LangGraph features a persistence layer that enables human-in-the-loop interactions, and it excels at building complex (i.e. more than a single LLM call) applications that require highly domain-specific cognitive architecture. Most of the agents we see in production fit this description.LangGraph is fully open source, available in both Python and Javascript. It works with or without LangChain, and integrates seamlessly with LangSmith.LangGraph Studio: Visualize and interact with agent graphs for quick iterationWhile LangGraph offers a new framework for developing agentic applications, we also strongly believe that new tooling is needed to make the development process easier. Building LLM applications differs from traditional software development, requiring different tooling outside of the traditional code\n",
            "\n",
            "LLMs have paved the way for the development of new types of agentic applications ‚Äî and as LLM applications evolve, so must the tooling needed to efficiently develop them. Today, we're announcing LangGraph Studio - the first IDE designed specifically for agent development - in open beta.LangGraph Studio offers a new way to develop LLM applications, providing a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. In this blog, we'll give a brief overview of LangGraph and then explore how LangGraph Studio streamlines the development of agentic applications.LangGraph: Balancing agent control with agency  In January 2023, we launched LangGraph, a highly controllable, low-level orchestration framework for building agentic applications. Since then, we've seen  teams build more complex agentic applications for production; in turn, we've heavily invested in LangGraph, leading to a stable 0.1 release this past June.LangGraph features a\n",
            "\n",
            "(or the logic underlying a specific node) halfway through the agent's trajectory. This creates an iterative process, by letting you interact with and manipulate the state at that point in time.While there is much more to explore, we're excited to introduce LangGraph Studio to start with bringing some of the core features of an agent IDE to the world.How to use LangGraph StudioLangGraph Studio is a desktop app, currently available for Apple Silicon. You can download a version here. Support for more platforms is coming soon.After you download and open LangGraph Studio, you will be prompted to log in with your LangSmith account. All users of LangSmith (including those with free accounts) currently have access to LangGraph Studio while it is in beta. You can sign up for a LangSmith account here.After downloading LangSmith, you can open a directory. At a bare minimum, this directory needs to contain a Python file with a graph defined in it. Next, you will need to create a langgraph.json\u001b[0m\u001b[32;1m\u001b[1;3mLangGraph Studio is the first IDE designed specifically for agent development. It provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. LangGraph Studio streamlines the development of agentic applications by offering a new way to develop LLM applications. LangGraph itself is a highly controllable, low-level orchestration framework for building agentic applications. It features a persistence layer that enables human-in-the-loop interactions and excels at building complex applications that require highly domain-specific cognitive architecture. LangGraph is fully open-source, available in both Python and JavaScript, and works with or without LangChain, integrating seamlessly with LangSmith.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is LangGraph',\n",
              " 'output': 'LangGraph Studio is the first IDE designed specifically for agent development. It provides a specialized agent IDE for visualizing, interacting with, and debugging complex agentic applications. LangGraph Studio streamlines the development of agentic applications by offering a new way to develop LLM applications. LangGraph itself is a highly controllable, low-level orchestration framework for building agentic applications. It features a persistence layer that enables human-in-the-loop interactions and excels at building complex applications that require highly domain-specific cognitive architecture. LangGraph is fully open-source, available in both Python and JavaScript, and works with or without LangChain, integrating seamlessly with LangSmith.'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\":\"What is weather in new york\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqw_Bn4O0P3m",
        "outputId": "accfab4e-689a-4a44-abea-f3319abdb9e6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': 'weather in New York'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New York', 'region': 'New York', 'country': 'United States of America', 'lat': 40.7142, 'lon': -74.0064, 'tz_id': 'America/New_York', 'localtime_epoch': 1737270567, 'localtime': '2025-01-19 02:09'}, 'current': {'last_updated_epoch': 1737270000, 'last_updated': '2025-01-19 02:00', 'temp_c': 4.4, 'temp_f': 39.9, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 5.1, 'wind_kph': 8.3, 'wind_degree': 295, 'wind_dir': 'WNW', 'pressure_mb': 1009.0, 'pressure_in': 29.79, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 83, 'cloud': 0, 'feelslike_c': 2.4, 'feelslike_f': 36.2, 'windchill_c': -0.7, 'windchill_f': 30.7, 'heatindex_c': 2.7, 'heatindex_f': 36.9, 'dewpoint_c': 1.5, 'dewpoint_f': 34.7, 'vis_km': 13.0, 'vis_miles': 8.0, 'uv': 0.0, 'gust_mph': 9.3, 'gust_kph': 15.0}}\"}, {'url': 'https://www.silive.com/weather/2025/01/nyc-weather-forecast-maps-show-latest-snow-total-projections-impact-and-timeline-of-sundays-winter-storm.html', 'content': 'NYC weather: Forecast maps show latest snow total projections, impact and timeline of Sunday’s winter storm - silive.com An AccuWeather graphic shows the forecast track of a winter storm set to impact New York City on Sunday, Jan. 19, 2025. As of Saturday afternoon, the National Weather Service believes Staten Island and the city will receive around four inches of snow; the figure falls within AccuWeather’s predicted snowfall range of three to six inches for the city. A National Weather Service graphic shows the percent chance of at least four inches of snow in New York City from Saturday, Jan. 18, through Tuesday, Jan. 21, 2025. A National Weather Service graphic shows forecast snowfall amounts in New York City from Saturday, Jan. 18, through Tuesday, Jan. 21, 2025.'}, {'url': 'https://world-weather.info/forecast/usa/new_york/january-2025/', 'content': \"Weather in New York City in January 2025 (New York) - Detailed Weather Forecast for a Month Weather in New York City Weather in New York City in January 2025 New York City Weather Forecast for January 2025 is based on long term prognosis and previous years' statistical data. 1 +50°+50° 2 +41°+39° 3 +37°+32° 4 +30°+30° 5 +30°+27° 6 +43°+30° 7 +37°+37° 8 +43°+34° 9 +32°+30° 10 +30°+28° 11 +41°+30° +46°+37° +45°+37° +36°+28° +37°+30° +39°+32° +36°+28° +39°+30° +39°+32° +37°+30° +36°+27° +37°+30° +39°+32° +39°+32° +41°+34° +39°+32° +41°+34° +39°+34° +41°+34° +36°+28° +36°+28° Extended weather forecast in New York City Albany+16° Linden+34° Yonkers+30° Mount Vernon+32° Paterson+30° Livingston+27° New Rochelle+32° Summit+27° Union+34° Clifton+32° Jersey City+34° Bayonne+34° East New York+36° Guttenberg+34° world's temperature today Temperature units\"}, {'url': 'https://world-weather.info/forecast/usa/new_york/19-january/', 'content': 'Weather in New York City Weather in New York City, January 19 Weather Forecast for January 19 in New York City, New York - temperature, wind, atmospheric pressure, humidity and precipitations. Night   +34°    +34°    30  2.9 67% Day +28°    +21°    29.7    6.9 69% Meteorological sensitivity index    1   Weather situation is generally favorable to meteosensitive people. Night   +43°    +39°    30  5.6 87% Day +41°    +39°    29.9    3.6 93% Meteorological sensitivity index    4   Strong reactions to the weather are possible by meteosensitive people. Geomagnetic conditions  2   Solar activity may affect some sensitive people. Night   +32°    +28°    30.2    3.6 81% Day +45°    +39°    30  8.3 51% Meteorological sensitivity index    3   Meteosensitive people are likely to experience weather-related symptoms. Geomagnetic conditions  2   Solar activity may affect some sensitive people.'}, {'url': 'https://world-weather.info/forecast/usa/manhattan_3/january-2025/', 'content': \"Weather in Manhattan in January 2025 (New York) - Detailed Weather Forecast for a Month Weather Weather in Manhattan Weather in Manhattan in January 2025 Manhattan Weather Forecast for January 2025 is based on long term prognosis and previous years' statistical data. 1 +50°+50° 2 +41°+39° 3 +37°+32° 4 +30°+30° 5 +30°+27° 6 +43°+30° 7 +37°+37° 8 +43°+34° 9 +32°+30° 10 +30°+28° 11 +41°+30° +46°+37° +45°+37° +36°+28° +37°+30° +39°+32° +36°+28° +39°+30° +39°+32° +37°+30° +36°+27° +37°+30° +39°+32° +39°+32° +41°+34° +39°+32° +41°+34° +39°+34° +41°+34° +36°+28° +36°+28° Extended weather forecast in Manhattan HourlyWeek10-Day14-Day30-DayBiometeo... Weather in Washington, D.C.+36° Albany+16° Linden+34° Yonkers+30° Mount Vernon+32° Paterson+30° Livingston+27° New Rochelle+32° Summit+27° Rockville Centre+36° Union+34° Clifton+32° Jersey City+34° Bayonne+34° North Bergen+34° East New York+36° West Long Branch+32° Nepperhan+30° world's temperature today day day Temperature units\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in New York is as follows:\n",
            "- Temperature: 39.9°F (4.4°C)\n",
            "- Condition: Clear\n",
            "- Wind: 5.1 mph from WNW\n",
            "- Humidity: 83%\n",
            "- Visibility: 8.0 miles\n",
            "\n",
            "For more detailed forecasts and information, you can visit [Weather API](https://www.weatherapi.com/).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is weather in new york',\n",
              " 'output': 'The current weather in New York is as follows:\\n- Temperature: 39.9°F (4.4°C)\\n- Condition: Clear\\n- Wind: 5.1 mph from WNW\\n- Humidity: 83%\\n- Visibility: 8.0 miles\\n\\nFor more detailed forecasts and information, you can visit [Weather API](https://www.weatherapi.com/).'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REACT Agent"
      ],
      "metadata": {
        "id": "xPghJHK41M22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "google_search = SerpAPIWrapper()"
      ],
      "metadata": {
        "id": "UHQ5A9vWzzlR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=google_search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\",\n",
        "        verbose=True\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "1r9jXuWb2ekY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
        "{tools}\n",
        "Use the following format:\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "Begin!\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}'''"
      ],
      "metadata": {
        "id": "ywaR3-qH3iSX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "bbLBGXl43jZV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_agent = create_react_agent(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    prompt=prompt\n",
        ")"
      ],
      "metadata": {
        "id": "sAU_WnDU3oXT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(agent=search_agent, tools=tools, verbose=True,return_intermediate_steps=True)"
      ],
      "metadata": {
        "id": "gX7bqb_93rtS"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\": \"Where is the hometown of the 2007 US PGA championship winner and his score?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqVkRHfQ3xy2",
        "outputId": "030ff354-bd73-49e0-f8bc-3d9e6db2c7a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should search for the hometown of the 2007 US PGA championship winner and his score.\n",
            "Action: Search\n",
            "Action Input: \"2007 US PGA championship winner hometown and score\"\u001b[0m\u001b[36;1m\u001b[1;3m['1. United States · Tiger Woods, 71-63-69-69=272 ; 2. United States · Woody Austin, 68-70-69-67=274 ; 3. South Africa · Ernie Els, 72-68-69-66=275 ; T4. United ...', '2007 PGA Championship Final Scores ; Tiger Woods, 71-63-69-69—272 ; Woody Austin, 68-70-69-67—274 ; Ernie Els, 72-68-69-66—275 ; John Senden, 69-70-69-71—279 ; Arron ...', 'When Tiger Woods parred the final hole to claim the 2007 PGA Championship at Southern Hills, it gave him his 13th Major win in just over a ...', \"Tiger Woods stretched his lead to three shots after the third round of the 89th US PGA Championship to stand on the verge of capturing the season's final ...\", 'The 2007 United States Open Championship was the 107th US Open, held June 14–17 at Oakmont Country Club in Oakmont, Pennsylvania, a suburb northeast of ...', \"Woods captured his fourth PGA Championship in 2007, topping Woody Austin by two shots. Austin made it interesting on the back nine making birdies on No's 11-13.\", 'PGA Championship - Winners, Records, History: Winners of the PGA Championship are provided in the table.', 'The 89th installment of the PGA Championship starts this Thursday at Southern Hills Golf Club in Tulsa, Oklahoma. Southern Hills will be the ...', 'Mickelson also won the BellSouth Classic the week prior with a remarkable score of 28-under-par. Geoff Ogilvy broke through with wins at the World Golf ...', 'Jack Nicklaus holds the record with with five stroke-play wins in this major. List of PGA Championship Winners. Here is the list of PGA Championship winners.']\u001b[0m\u001b[32;1m\u001b[1;3mI should look for the specific information about the 2007 US PGA championship winner's hometown and score from the search results.\n",
            "Action: Search\n",
            "Action Input: \"2007 US PGA championship winner hometown and score Tiger Woods\"\u001b[0m\u001b[36;1m\u001b[1;3m['Friday, August 10, 2007. Tiger Woods scored a 63, tying the record for the lowest single-round score at a major championship. The feat had been previously ...', \"Woods captured his fourth PGA Championship in 2007, topping Woody Austin by two shots. Austin made it interesting on the back nine making birdies on No's 11-13.\", 'Tiger Woods returned to Tulsa for the 2007 PGA Championship having played at Southern Hills twice before.', 'Eldrick Tont \"Tiger\" Woods (born December 30, 1975) is an American professional golfer. He is tied for first in PGA Tour wins, ranks second in men\\'s major ...', '17 years ago this week at Southern Hills, Tiger Woods won his 13th major by two strokes over Woody Austin for his second straight PGA title.', 'Hometown: Jupiter, FL; College: Stanford University; Height: 6 ft 1 ... About Us · Contact Us · Privacy Policy · Terms of Service · Do Not Sell or ...', \"Tiger Woods beats Steve Stricker by two strokes to claim victory at Quail Hollow Club for his 57th career win. Tiger Woods' chase for Sam ...\", \"In '99, Sergio Garcia and Tiger Woods wowed the fans in at Medinah, with a battle that was not only memorable and impressive, but extremely fun ...\", 'Tiger Woods holds the PGA Championship trophy at Southern Hills Country Club, Sunday, Aug. 12, 2007. Tulsa World Archive. 2007 PGA Championship.', 'Woods followed it up with two-straight rounds of 69 to hold off the likes of Ernie Els and Woody Austin with a final score of 8-under par. \"If ...']\u001b[0m\u001b[32;1m\u001b[1;3mI have found the information about the 2007 US PGA championship winner's hometown and score.\n",
            "Final Answer: The 2007 US PGA championship winner was Tiger Woods, with a score of 272, and his hometown is Jupiter, Florida.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Where is the hometown of the 2007 US PGA championship winner and his score?',\n",
              " 'output': 'The 2007 US PGA championship winner was Tiger Woods, with a score of 272, and his hometown is Jupiter, Florida.',\n",
              " 'intermediate_steps': [(AgentAction(tool='Search', tool_input='2007 US PGA championship winner hometown and score', log='I should search for the hometown of the 2007 US PGA championship winner and his score.\\nAction: Search\\nAction Input: \"2007 US PGA championship winner hometown and score\"'),\n",
              "   '[\\'1. United States · Tiger Woods, 71-63-69-69=272 ; 2. United States · Woody Austin, 68-70-69-67=274 ; 3. South Africa · Ernie Els, 72-68-69-66=275 ; T4. United ...\\', \\'2007 PGA Championship Final Scores ; Tiger Woods, 71-63-69-69—272 ; Woody Austin, 68-70-69-67—274 ; Ernie Els, 72-68-69-66—275 ; John Senden, 69-70-69-71—279 ; Arron ...\\', \\'When Tiger Woods parred the final hole to claim the 2007 PGA Championship at Southern Hills, it gave him his 13th Major win in just over a ...\\', \"Tiger Woods stretched his lead to three shots after the third round of the 89th US PGA Championship to stand on the verge of capturing the season\\'s final ...\", \\'The 2007 United States Open Championship was the 107th US Open, held June 14–17 at Oakmont Country Club in Oakmont, Pennsylvania, a suburb northeast of ...\\', \"Woods captured his fourth PGA Championship in 2007, topping Woody Austin by two shots. Austin made it interesting on the back nine making birdies on No\\'s 11-13.\", \\'PGA Championship - Winners, Records, History: Winners of the PGA Championship are provided in the table.\\', \\'The 89th installment of the PGA Championship starts this Thursday at Southern Hills Golf Club in Tulsa, Oklahoma. Southern Hills will be the ...\\', \\'Mickelson also won the BellSouth Classic the week prior with a remarkable score of 28-under-par. Geoff Ogilvy broke through with wins at the World Golf ...\\', \\'Jack Nicklaus holds the record with with five stroke-play wins in this major. List of PGA Championship Winners. Here is the list of PGA Championship winners.\\']'),\n",
              "  (AgentAction(tool='Search', tool_input='2007 US PGA championship winner hometown and score Tiger Woods', log='I should look for the specific information about the 2007 US PGA championship winner\\'s hometown and score from the search results.\\nAction: Search\\nAction Input: \"2007 US PGA championship winner hometown and score Tiger Woods\"'),\n",
              "   '[\\'Friday, August 10, 2007. Tiger Woods scored a 63, tying the record for the lowest single-round score at a major championship. The feat had been previously ...\\', \"Woods captured his fourth PGA Championship in 2007, topping Woody Austin by two shots. Austin made it interesting on the back nine making birdies on No\\'s 11-13.\", \\'Tiger Woods returned to Tulsa for the 2007 PGA Championship having played at Southern Hills twice before.\\', \\'Eldrick Tont \"Tiger\" Woods (born December 30, 1975) is an American professional golfer. He is tied for first in PGA Tour wins, ranks second in men\\\\\\'s major ...\\', \\'17 years ago this week at Southern Hills, Tiger Woods won his 13th major by two strokes over Woody Austin for his second straight PGA title.\\', \\'Hometown: Jupiter, FL; College: Stanford University; Height: 6 ft 1 ... About Us · Contact Us · Privacy Policy · Terms of Service · Do Not Sell or ...\\', \"Tiger Woods beats Steve Stricker by two strokes to claim victory at Quail Hollow Club for his 57th career win. Tiger Woods\\' chase for Sam ...\", \"In \\'99, Sergio Garcia and Tiger Woods wowed the fans in at Medinah, with a battle that was not only memorable and impressive, but extremely fun ...\", \\'Tiger Woods holds the PGA Championship trophy at Southern Hills Country Club, Sunday, Aug. 12, 2007. Tulsa World Archive. 2007 PGA Championship.\\', \\'Woods followed it up with two-straight rounds of 69 to hold off the likes of Ernie Els and Woody Austin with a final score of 8-under par. \"If ...\\']')]}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReAct Agent with Custom tools\n"
      ],
      "metadata": {
        "id": "pulvr8eu5hVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom tool for the Agent\n",
        "@tool\n",
        "def get_employee_id(name):\n",
        "  \"\"\"\n",
        "  To get employee id, it takes employee name as arguments\n",
        "  name(str): Name of the employee\n",
        "  \"\"\"\n",
        "  fake_employees = {\n",
        "    \"Alice\": \"E001\",\n",
        "    \"Bob\": \"E002\",\n",
        "    \"Charlie\": \"E003\",\n",
        "    \"Diana\": \"E004\",\n",
        "    \"Evan\": \"E005\",\n",
        "    \"Fiona\": \"E006\",\n",
        "    \"George\": \"E007\",\n",
        "    \"Hannah\": \"E008\",\n",
        "    \"Ian\": \"E009\",\n",
        "    \"Jasmine\": \"E010\"}\n",
        "\n",
        "  return fake_employees.get(name,\"Employee not found\")# Custom tool for the Agent"
      ],
      "metadata": {
        "id": "6LWyvUKc4nXY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom tool for the Agent\n",
        "@tool\n",
        "def get_employee_salary(employee_id):\n",
        "  \"\"\"\n",
        "  To get the salary of an employee, it takes employee_id as input and return salary\n",
        "  \"\"\"\n",
        "  employee_salaries = {\n",
        "    \"E001\": 56000,\n",
        "    \"E002\": 47000,\n",
        "    \"E003\": 52000,\n",
        "    \"E004\": 61000,\n",
        "    \"E005\": 45000,\n",
        "    \"E006\": 58000,\n",
        "    \"E007\": 49000,\n",
        "    \"E008\": 53000,\n",
        "    \"E009\": 50000,\n",
        "    \"E010\": 55000\n",
        "    }\n",
        "  return employee_salaries.get(employee_id,\"Employee not found\")"
      ],
      "metadata": {
        "id": "7zcOGk8i8Q-I"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"hwchase17/react\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-aH87gO8WMW",
        "outputId": "db10fb05-a21d-41a8-b4bb-6779fe57822e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL0gMQ7P8Xoo",
        "outputId": "9933a89c-c9e0-4716-8f47-1e8512453d0a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [get_employee_salary, get_employee_id]"
      ],
      "metadata": {
        "id": "ic7RepG-8aGA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(llm,tools,prompt)"
      ],
      "metadata": {
        "id": "kCNIqXsX8cPI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True)"
      ],
      "metadata": {
        "id": "5nqlSCnE8dgS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\":\"What is the Salary of Evan?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cld_G7T8e68",
        "outputId": "1f288166-c67a-4dc8-8919-ca2396a1b72b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to first get the employee ID of Evan.\n",
            "Action: get_employee_id\n",
            "Action Input: name = \"Evan\"\u001b[0m\u001b[33;1m\u001b[1;3mEmployee not found\u001b[0m\u001b[32;1m\u001b[1;3mIt seems that the employee ID for Evan is not found. Perhaps Evan is not an employee in the database.\n",
            "Final Answer: Employee not found\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the Salary of Evan?', 'output': 'Employee not found'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Ask with Search Agent"
      ],
      "metadata": {
        "id": "3kKp7bmx71JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "54M1URHD9lcv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Intermediate Answer\",\n",
        "        func=google_search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\",\n",
        "        verbose=True\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "manOr_D874Tv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"hwchase17/self-ask-with-search\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVxSXrAY8Iqh",
        "outputId": "cb4af36a-7a78-48de-a41a-bf281d608e98"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "jGJp1sAa8Kha",
        "outputId": "d68dba01-28a0-42ec-adb5-a7e527219b0d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: Who lived longer, Muhammad Ali or Alan Turing?\\nAre follow up questions needed here: Yes.\\nFollow up: How old was Muhammad Ali when he died?\\nIntermediate answer: Muhammad Ali was 74 years old when he died.\\nFollow up: How old was Alan Turing when he died?\\nIntermediate answer: Alan Turing was 41 years old when he died.\\nSo the final answer is: Muhammad Ali\\n\\nQuestion: When was the founder of craigslist born?\\nAre follow up questions needed here: Yes.\\nFollow up: Who was the founder of craigslist?\\nIntermediate answer: Craigslist was founded by Craig Newmark.\\nFollow up: When was Craig Newmark born?\\nIntermediate answer: Craig Newmark was born on December 6, 1952.\\nSo the final answer is: December 6, 1952\\n\\nQuestion: Who was the maternal grandfather of George Washington?\\nAre follow up questions needed here: Yes.\\nFollow up: Who was the mother of George Washington?\\nIntermediate answer: The mother of George Washington was Mary Ball Washington.\\nFollow up: Who was the father of Mary Ball Washington?\\nIntermediate answer: The father of Mary Ball Washington was Joseph Ball.\\nSo the final answer is: Joseph Ball\\n\\nQuestion: Are both the directors of Jaws and Casino Royale from the same country?\\nAre follow up questions needed here: Yes.\\nFollow up: Who is the director of Jaws?\\nIntermediate answer: The director of Jaws is Steven Spielberg.\\nFollow up: Where is Steven Spielberg from?\\nIntermediate answer: The United States.\\nFollow up: Who is the director of Casino Royale?\\nIntermediate answer: The director of Casino Royale is Martin Campbell.\\nFollow up: Where is Martin Campbell from?\\nIntermediate answer: New Zealand.\\nSo the final answer is: No\\n\\nQuestion: {input}\\nAre followup questions needed here:{agent_scratchpad}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_self_ask_with_search_agent(llm,tools,prompt)"
      ],
      "metadata": {
        "id": "9YpK6pHH87LF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True,handle_parsing_errors=True)"
      ],
      "metadata": {
        "id": "5-Lra_PF8-gM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    {\"input\":\"Which asian country has largest population?\"}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSf0K7Ad9Ky0",
        "outputId": "d9c7dde7-b2d1-4e71-b083-840736f40bf7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYes.\n",
            "Follow up: What are the most populous Asian countries?\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Asian Countries by Population (2025) - Worldometer', 'source': 'Worldometer', 'description': 'Asian Countries by population (2025)'}\u001b[0m\u001b[32;1m\u001b[1;3mSo the final answer is:  This answer is incomplete.  The follow-up question only provides a source to find the answer, not the answer itself.  To complete the answer, one would need to consult the Worldometer link and determine which Asian country has the largest population.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Which asian country has largest population?',\n",
              " 'output': ' This answer is incomplete.  The follow-up question only provides a source to find the answer, not the answer itself.  To complete the answer, one would need to consult the Worldometer link and determine which Asian country has the largest population.'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    {\"input\":\"Who is current captain of indian men's cricket team?\"}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvYg7VWl9Tlf",
        "outputId": "8c148ebe-873b-428f-94d3-2093fef1ca4d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYes.\n",
            "Follow up: What is the name of the Indian men's cricket team?\u001b[0m\u001b[36;1m\u001b[1;3mthe Men in Blue\u001b[0m\u001b[32;1m\u001b[1;3mSo the final answer is:  The question cannot be answered with the given information.  The follow-up question did not lead to the answer.  A better follow-up would have been \"Who is the current captain of the Indian men's cricket team?\"\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"Who is current captain of indian men's cricket team?\",\n",
              " 'output': ' The question cannot be answered with the given information.  The follow-up question did not lead to the answer.  A better follow-up would have been \"Who is the current captain of the Indian men\\'s cricket team?\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}